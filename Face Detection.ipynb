{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "edbd31a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "import io\n",
    "import glob\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import uuid\n",
    "import requests\n",
    "from urllib.parse import urlparse\n",
    "from io import BytesIO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "34bcca4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image, ImageDraw\n",
    "from azure.cognitiveservices.vision.face import FaceClient\n",
    "from msrest.authentication import CognitiveServicesCredentials\n",
    "from azure.cognitiveservices.vision.face.models import TrainingStatusType, Person"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e146b8e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This key will serve all examples in this document.\n",
    "KEY = \"a14f57d8ef184afead06deec4e3cc2d5\"\n",
    "\n",
    "# This endpoint will be used in all examples in this quickstart.\n",
    "ENDPOINT = \"https://myedunetapi.cognitiveservices.azure.com/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b44eaf2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an authenticated FaceClient.\n",
    "face_client = FaceClient(ENDPOINT, CognitiveServicesCredentials(KEY))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e7d4b63e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected face ID from GettyImages-1225292516.jpg :\n",
      "25e923a0-423b-4f35-a530-5b825978f792\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Detect a face in an image that contains a single face\n",
    "single_face_image_url = 'https://assets.teenvogue.com/photos/5ec13231a575717f045cbec3/16:9/w_2560%2Cc_limit/GettyImages-1225292516.jpg'\n",
    "single_image_name = os.path.basename(single_face_image_url)\n",
    "# We use detection model 3 to get better performance.\n",
    "detected_faces = face_client.face.detect_with_url(url=single_face_image_url, detection_model='detection_03')\n",
    "if not detected_faces:\n",
    "    raise Exception('No face detected from image {}'.format(single_image_name))\n",
    "\n",
    "# Display the detected face ID in the first single-face image.\n",
    "# Face IDs are used for comparison to faces (their IDs) detected in other images.\n",
    "print('Detected face ID from', single_image_name, ':')\n",
    "for face in detected_faces: print (face.face_id)\n",
    "print()\n",
    "\n",
    "# Save this ID for use in Find Similar\n",
    "first_image_face_ID = detected_faces[0].face_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "037651b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drawing rectangle around face... see popup for results.\n"
     ]
    }
   ],
   "source": [
    "# Detect a face in an image that contains a single face\n",
    "single_face_image_url = 'https://assets.teenvogue.com/photos/5ec13231a575717f045cbec3/16:9/w_2560%2Cc_limit/GettyImages-1225292516.jpg'\n",
    "single_image_name = os.path.basename(single_face_image_url)\n",
    "# We use detection model 3 to get better performance.\n",
    "detected_faces = face_client.face.detect_with_url(url=single_face_image_url, detection_model='detection_03')\n",
    "if not detected_faces:\n",
    "    raise Exception('No face detected from image {}'.format(single_image_name))\n",
    "\n",
    "# Convert width height to a point in a rectangle\n",
    "def getRectangle(faceDictionary):\n",
    "    rect = faceDictionary.face_rectangle\n",
    "    left = rect.left\n",
    "    top = rect.top\n",
    "    right = left + rect.width\n",
    "    bottom = top + rect.height\n",
    "    \n",
    "    return ((left, top), (right, bottom))\n",
    "\n",
    "def drawFaceRectangles() :\n",
    "# Download the image from the url\n",
    "    response = requests.get(single_face_image_url)\n",
    "    img = Image.open(BytesIO(response.content))\n",
    "\n",
    "# For each face returned use the face rectangle and draw a red box.\n",
    "    print('Drawing rectangle around face... see popup for results.')\n",
    "    draw = ImageDraw.Draw(img)\n",
    "    for face in detected_faces:\n",
    "        draw.rectangle(getRectangle(face), outline='red')\n",
    "\n",
    "# Display the image in the default image browser.\n",
    "    img.show()\n",
    "\n",
    "# Uncomment this to show the face rectangles.\n",
    "drawFaceRectangles()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33e5f439",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
